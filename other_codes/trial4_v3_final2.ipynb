{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = 'stage3_data_cleaning/v2/type1_label_merged_final_decoded_clean3.xlsx'\n",
    "data = pd.read_excel(data_path)\n",
    "data['can_id'] = data['can_id'].astype(str)\n",
    "\n",
    "output_dir = \"can_graphs/v8\"\n",
    "visualization_dir = os.path.join(output_dir, \"visualizations\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(visualization_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optimized_pagerank(G, damping_factor=0.7):\n",
    "    N = len(G)\n",
    "    pagerank = {node: 1 / N for node in G}\n",
    "    for _ in range(100):  # Iterate 100 times for convergence\n",
    "        new_pagerank = {}\n",
    "        for node in G:\n",
    "            rank_sum = 0\n",
    "            for neighbor in G.predecessors(node):\n",
    "                weight_sum = sum([G[neighbor][succ]['weight'] for succ in G.successors(neighbor)])\n",
    "                rank_sum += pagerank[neighbor] * (G[neighbor][node]['weight'] / weight_sum)\n",
    "            new_pagerank[node] = (1 - damping_factor) / N + damping_factor * rank_sum\n",
    "        pagerank = new_pagerank\n",
    "    nx.set_node_attributes(G, pagerank, 'pagerank')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(window_df):\n",
    "    G = nx.DiGraph()\n",
    "    index_tracker = {}\n",
    "    \n",
    "    for i in range(len(window_df) - 1):\n",
    "        node1 = window_df.iloc[i]['can_id']\n",
    "        node2 = window_df.iloc[i + 1]['can_id']\n",
    "        timestamp_diff = window_df.iloc[i + 1]['timestamp'] - window_df.iloc[i]['timestamp']\n",
    "        label = window_df.iloc[i]['label']\n",
    "        transfer_id1 = window_df.iloc[i]['transfer_ID']\n",
    "        transfer_id2 = window_df.iloc[i + 1]['transfer_ID']\n",
    "        \n",
    "        if node1 != node2 or transfer_id1 != transfer_id2:  # Avoid self-loops\n",
    "            if G.has_edge(node1, node2):\n",
    "                G[node1][node2]['weight'] += timestamp_diff\n",
    "            else:\n",
    "                G.add_edge(node1, node2, weight=timestamp_diff)\n",
    "        \n",
    "        if node1 not in index_tracker:\n",
    "            index_tracker[node1] = []\n",
    "        index_tracker[node1].append((i, label))\n",
    "        \n",
    "        # if i == len(window_df)-1:\n",
    "        if node2 not in index_tracker:\n",
    "            index_tracker[node2] = []\n",
    "        index_tracker[node2].append((i, label))\n",
    "\n",
    "    index_tracker = {k: sorted(list(v)) for k, v in index_tracker.items()}\n",
    "    \n",
    "    # print(index_tracker)\n",
    "    # index_tracker = {k: sorted(list(v)) for k, v in index_tracker.items()}\n",
    "    # print(index_tracker)\n",
    "    # Calculate PageRank and in-degree\n",
    "    pagerank = calculate_optimized_pagerank(G)\n",
    "    indegree = dict(G.in_degree())\n",
    "    \n",
    "    for node in G.nodes:\n",
    "        # G.nodes[node]['pagerank'] = pagerank.get(node, 0.0)\n",
    "        G.nodes[node]['indegree'] = indegree.get(node, 0)\n",
    "    \n",
    "    return G, index_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the graph and save to file\n",
    "def visualize_graph(G, window_index):\n",
    "    pos = nx.spring_layout(G)\n",
    "    pagerank = nx.get_node_attributes(G, 'pagerank')\n",
    "    indegree = nx.get_node_attributes(G, 'indegree')\n",
    "    labels = {node: f'{node}\\nPR: {pagerank[node]:.2f}\\nInDeg: {indegree[node]}' for node in G.nodes()}\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw(G, pos, with_labels=True, labels=labels, node_size=7000, node_color='skyblue', font_size=10, edge_color='gray')\n",
    "    plt.title(f\"Graph for Window {window_index}\")\n",
    "    output_path = os.path.join(visualization_dir, f'graph_window_{window_index}.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def preprocess_data(data, window_size=100):\n",
    "    pyg_data_list = []\n",
    "    for window_start in tqdm(range(0, len(data), window_size)):\n",
    "        window_end = min(window_start + window_size, len(data))\n",
    "        window_data = data.iloc[window_start:window_end]\n",
    "        G, index_tracker = create_graph(window_data)\n",
    "        # break\n",
    "        # Convert networkx graph to PyG data object\n",
    "        pyg_data = from_networkx(G, group_node_attrs=['pagerank', 'indegree'])\n",
    "\n",
    "        pyg_data.x = pyg_data.x.float()\n",
    "        \n",
    "        # Add labels to PyG data object\n",
    "        labels = []\n",
    "        for node in G.nodes:\n",
    "            # Use the most recent label for each node\n",
    "            labels.append(index_tracker[node][-1][1])\n",
    "        pyg_data.y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        # Save the raw graph for later analysis\n",
    "        graph_path = os.path.join(output_dir, f'graph_window_{window_start // window_size}.gpickle')\n",
    "        # nx.write_gpickle(G, graph_path)\n",
    "        nx.write_graphml(G, graph_path)\n",
    "        \n",
    "        # Save the visualization of the graph\n",
    "        visualize_graph(G, window_start // window_size)\n",
    "        \n",
    "        \n",
    "        pyg_data_list.append(pyg_data)\n",
    "    \n",
    "    return pyg_data_list\n",
    "\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data in test_loader:\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        y_true.extend(data.y.tolist())\n",
    "        y_pred.extend(pred.tolist())\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    return cm, report\n",
    "\n",
    "# Save the model\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "class EGraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_data_list = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(0.7 * len(pyg_data_list))\n",
    "train_data = pyg_data_list[:train_size]\n",
    "test_data = pyg_data_list[train_size:]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "model = EGraphSAGE(in_channels=2, hidden_channels=128, out_channels=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, report = evaluate_model(model, test_loader)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, os.path.join(output_dir, 'graphsage_model_optimized_pagerank.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uavcan_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
