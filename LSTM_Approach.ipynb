{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045363dd-64d5-439f-b6ba-0cb545f9affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f39f019-35e4-4ee9-8e13-97bd1ad24b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18b1ad4-11e0-42f0-be14-aa629c3fd102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stage3_data_cleaning/v2\\\\type10_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type1_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type2_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type3_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type4_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type5_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type6_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type7_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type8_label_merged_final_decoded_clean3.xlsx',\n",
       " 'stage3_data_cleaning/v2\\\\type9_label_merged_final_decoded_clean3.xlsx']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean_folder = \"stage3_data_cleaning/v2\"\n",
    "folder_path = data_clean_folder\n",
    "xlsx_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n",
    "xlsx_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8568328c-3878-44a3-a088-38305988b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_excel(xlsx_files[1])\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2949e26c-7a77-4b7b-80f2-d15163a78602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_threshold = math.ceil(0.6 * max(df['timestamp']))\n",
    "# val_threshold = math.ceil(0.8 * max(df['timestamp']))\n",
    "# train_threshold,val_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f7c2f4-b69c-404f-ab69-78375984c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4562a85e-60e3-4b8a-a62d-e0f565fcab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = data[data['timestamp'] <= train_threshold]\n",
    "# val_data = data[(data['timestamp'] > train_threshold) & (data['timestamp'] <= val_threshold)]\n",
    "# test_data = data[data['timestamp'] > val_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191904fb-3cd5-46e9-a3de-144558e324b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train_data.drop(['label', 'timestamp','can_id'], axis=1)\n",
    "# y_train = train_data['label']\n",
    "# X_val = val_data.drop(['label', 'timestamp','can_id'], axis=1)\n",
    "# y_val = val_data['label']\n",
    "# X_test = test_data.drop(['label', 'timestamp','can_id'], axis=1)\n",
    "# y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "277b55bc-6e8e-478d-9512-be9904aeb236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3841a4d5-9938-4d70-85eb-c706ef151ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "# X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
    "# X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cbf0081-76d4-4efa-82f2-176fecb7babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "# y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "# X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "# y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "# X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "# y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# print(f\"Train set: {X_train_tensor.shape}\")\n",
    "# print(f\"Validation set: {X_val_tensor.shape}\")\n",
    "# print(f\"Test set: {X_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f43d2032-521a-4b30-86b6-d75e35140f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# input_size = X_train_tensor.shape[2]\n",
    "# hidden_size = 50\n",
    "# num_layers = 2\n",
    "# output_size = 1\n",
    "\n",
    "# model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "690d25cb-841d-4e8d-9fe3-b760aad3378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "\n",
    "def lstm_approach(X_train_tensor,y_train_tensor,X_val_tensor,y_val_tensor,X_test_tensor,y_test_tensor):\n",
    "\n",
    "    input_size = X_train_tensor.shape[2]\n",
    "    hidden_size = 50\n",
    "    num_layers = 2\n",
    "    output_size = 1\n",
    "\n",
    "    model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "    print(model)\n",
    "    \n",
    "    # criterion = nn.MSELoss() # Regression LOSS\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    num_epochs = 100\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(X_train_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_predictions = (val_outputs > 0.5).float()\n",
    "        val_accuracy = accuracy_score(y_val_tensor.cpu(), val_predictions.cpu())\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    test_predictions = (test_outputs > 0.5).float()\n",
    "    test_accuracy = accuracy_score(y_test_tensor.cpu(), test_predictions.cpu())\n",
    "\n",
    "\n",
    "    val_outputs = model(X_val_tensor)\n",
    "    val_loss = criterion(val_outputs, y_val_tensor)\n",
    "    val_predictions = (val_outputs > 0.5).float()\n",
    "    val_accuracy = accuracy_score(y_val_tensor.cpu(), val_predictions.cpu())\n",
    "\n",
    "    return val_loss.item(),test_loss.item(),test_accuracy,val_accuracy,model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af99e565-c9be-41da-8e0f-ce2fc6a372cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_analysis_lstm(data):\n",
    "    train_threshold = math.ceil(0.6 * max(data['timestamp']))\n",
    "    val_threshold = math.ceil(0.8 * max(data['timestamp']))\n",
    "\n",
    "    train_data = data[data['timestamp'] <= train_threshold]\n",
    "    val_data = data[(data['timestamp'] > train_threshold) & (data['timestamp'] <= val_threshold)]\n",
    "    test_data = data[data['timestamp'] > val_threshold]\n",
    "\n",
    "    X_train = train_data.drop(['label', 'timestamp','can_id'], axis=1)\n",
    "    y_train = train_data['label']\n",
    "    X_val = val_data.drop(['label', 'timestamp','can_id'], axis=1)\n",
    "    y_val = val_data['label']\n",
    "    X_test = test_data.drop(['label', 'timestamp','can_id'], axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "    X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    print(f\"Train set: {X_train_tensor.shape}\")\n",
    "    print(f\"Validation set: {X_val_tensor.shape}\")\n",
    "    print(f\"Test set: {X_test_tensor.shape}\")\n",
    "\n",
    "    return X_train_tensor,y_train_tensor,X_val_tensor,y_val_tensor,X_test_tensor,y_test_tensor\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7abc382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be2f853b-7ed6-4908-9bcd-a6aac8fcf64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type10_label\n",
      "Train set: torch.Size([110047, 1, 19])\n",
      "Validation set: torch.Size([58848, 1, 19])\n",
      "Test set: torch.Size([38485, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6710, Val Loss: 0.7026, Val Accuracy: 0.4488\n",
      "Epoch [20/100], Loss: 0.6546, Val Loss: 0.7141, Val Accuracy: 0.4488\n",
      "Epoch [30/100], Loss: 0.6335, Val Loss: 0.7392, Val Accuracy: 0.4488\n",
      "Epoch [40/100], Loss: 0.6108, Val Loss: 0.7962, Val Accuracy: 0.4488\n",
      "Epoch [50/100], Loss: 0.6015, Val Loss: 0.8835, Val Accuracy: 0.4488\n",
      "Epoch [60/100], Loss: 0.6003, Val Loss: 0.8921, Val Accuracy: 0.4488\n",
      "Epoch [70/100], Loss: 0.5969, Val Loss: 0.8537, Val Accuracy: 0.4488\n",
      "Epoch [80/100], Loss: 0.5943, Val Loss: 0.8435, Val Accuracy: 0.4488\n",
      "Epoch [90/100], Loss: 0.5907, Val Loss: 0.8495, Val Accuracy: 0.4488\n",
      "Epoch [100/100], Loss: 0.5862, Val Loss: 0.8427, Val Accuracy: 0.4488\n",
      "{'dataset': 'type10_label', 'LSTM_VAL_LOSS': 0.8426910042762756, 'LSTM_VAL_ACC': 0.44878330614464385, 'LSTM_Test_LOSS': 0.6071075201034546, 'LSTM_Test_ACC': 0.6979082759516695}\n",
      "type1_label\n",
      "Train set: torch.Size([116922, 1, 19])\n",
      "Validation set: torch.Size([52591, 1, 19])\n",
      "Test set: torch.Size([38345, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6908, Val Loss: 0.6865, Val Accuracy: 0.6398\n",
      "Epoch [20/100], Loss: 0.6873, Val Loss: 0.6772, Val Accuracy: 0.6398\n",
      "Epoch [30/100], Loss: 0.6825, Val Loss: 0.6661, Val Accuracy: 0.6398\n",
      "Epoch [40/100], Loss: 0.6744, Val Loss: 0.6531, Val Accuracy: 0.6398\n",
      "Epoch [50/100], Loss: 0.6590, Val Loss: 0.6364, Val Accuracy: 0.6494\n",
      "Epoch [60/100], Loss: 0.6308, Val Loss: 0.6047, Val Accuracy: 0.7249\n",
      "Epoch [70/100], Loss: 0.5819, Val Loss: 0.5497, Val Accuracy: 0.8696\n",
      "Epoch [80/100], Loss: 0.5037, Val Loss: 0.4659, Val Accuracy: 0.9871\n",
      "Epoch [90/100], Loss: 0.3934, Val Loss: 0.3512, Val Accuracy: 0.9997\n",
      "Epoch [100/100], Loss: 0.2659, Val Loss: 0.2250, Val Accuracy: 1.0000\n",
      "{'dataset': 'type1_label', 'LSTM_VAL_LOSS': 0.2250070422887802, 'LSTM_VAL_ACC': 1.0, 'LSTM_Test_LOSS': 0.4227374792098999, 'LSTM_Test_ACC': 0.8195071065327943}\n",
      "type2_label\n",
      "Train set: torch.Size([76877, 1, 19])\n",
      "Validation set: torch.Size([30835, 1, 19])\n",
      "Test set: torch.Size([26458, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.7057, Val Loss: 0.6998, Val Accuracy: 0.2999\n",
      "Epoch [20/100], Loss: 0.6765, Val Loss: 0.6767, Val Accuracy: 0.7001\n",
      "Epoch [30/100], Loss: 0.6330, Val Loss: 0.6434, Val Accuracy: 0.7001\n",
      "Epoch [40/100], Loss: 0.5740, Val Loss: 0.6044, Val Accuracy: 0.7001\n",
      "Epoch [50/100], Loss: 0.5248, Val Loss: 0.5902, Val Accuracy: 0.7001\n",
      "Epoch [60/100], Loss: 0.5159, Val Loss: 0.6110, Val Accuracy: 0.7001\n",
      "Epoch [70/100], Loss: 0.5120, Val Loss: 0.6059, Val Accuracy: 0.7001\n",
      "Epoch [80/100], Loss: 0.5045, Val Loss: 0.5887, Val Accuracy: 0.7001\n",
      "Epoch [90/100], Loss: 0.4985, Val Loss: 0.5799, Val Accuracy: 0.7001\n",
      "Epoch [100/100], Loss: 0.4905, Val Loss: 0.5747, Val Accuracy: 0.7001\n",
      "{'dataset': 'type2_label', 'LSTM_VAL_LOSS': 0.5747380256652832, 'LSTM_VAL_ACC': 0.7001459380574023, 'LSTM_Test_LOSS': 0.46329575777053833, 'LSTM_Test_ACC': 0.799758107188752}\n",
      "type3_label\n",
      "Train set: torch.Size([110731, 1, 19])\n",
      "Validation set: torch.Size([48844, 1, 19])\n",
      "Test set: torch.Size([37904, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6928, Val Loss: 0.6916, Val Accuracy: 0.5829\n",
      "Epoch [20/100], Loss: 0.6892, Val Loss: 0.6929, Val Accuracy: 0.4388\n",
      "Epoch [30/100], Loss: 0.6835, Val Loss: 0.6921, Val Accuracy: 0.4388\n",
      "Epoch [40/100], Loss: 0.6728, Val Loss: 0.6857, Val Accuracy: 0.4389\n",
      "Epoch [50/100], Loss: 0.6532, Val Loss: 0.6685, Val Accuracy: 0.6074\n",
      "Epoch [60/100], Loss: 0.6215, Val Loss: 0.6397, Val Accuracy: 0.8405\n",
      "Epoch [70/100], Loss: 0.5777, Val Loss: 0.5979, Val Accuracy: 0.8818\n",
      "Epoch [80/100], Loss: 0.5214, Val Loss: 0.5371, Val Accuracy: 0.9019\n",
      "Epoch [90/100], Loss: 0.4507, Val Loss: 0.4557, Val Accuracy: 0.9129\n",
      "Epoch [100/100], Loss: 0.3718, Val Loss: 0.3631, Val Accuracy: 0.9220\n",
      "{'dataset': 'type3_label', 'LSTM_VAL_LOSS': 0.3631482422351837, 'LSTM_VAL_ACC': 0.9220170338219638, 'LSTM_Test_LOSS': 0.33469709753990173, 'LSTM_Test_ACC': 0.9317486281131279}\n",
      "type4_label\n",
      "Train set: torch.Size([76598, 1, 19])\n",
      "Validation set: torch.Size([30004, 1, 19])\n",
      "Test set: torch.Size([26772, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6530, Val Loss: 0.6601, Val Accuracy: 0.7300\n",
      "Epoch [20/100], Loss: 0.6293, Val Loss: 0.6418, Val Accuracy: 0.7300\n",
      "Epoch [30/100], Loss: 0.5984, Val Loss: 0.6196, Val Accuracy: 0.7300\n",
      "Epoch [40/100], Loss: 0.5614, Val Loss: 0.5985, Val Accuracy: 0.7300\n",
      "Epoch [50/100], Loss: 0.5334, Val Loss: 0.5956, Val Accuracy: 0.7300\n",
      "Epoch [60/100], Loss: 0.5252, Val Loss: 0.6050, Val Accuracy: 0.7300\n",
      "Epoch [70/100], Loss: 0.5179, Val Loss: 0.5974, Val Accuracy: 0.7300\n",
      "Epoch [80/100], Loss: 0.5103, Val Loss: 0.5863, Val Accuracy: 0.7300\n",
      "Epoch [90/100], Loss: 0.5025, Val Loss: 0.5790, Val Accuracy: 0.7300\n",
      "Epoch [100/100], Loss: 0.4928, Val Loss: 0.5715, Val Accuracy: 0.7300\n",
      "{'dataset': 'type4_label', 'LSTM_VAL_LOSS': 0.5715468525886536, 'LSTM_VAL_ACC': 0.7300359952006399, 'LSTM_Test_LOSS': 0.4719444513320923, 'LSTM_Test_ACC': 0.8121171373076348}\n",
      "type5_label\n",
      "Train set: torch.Size([106659, 1, 19])\n",
      "Validation set: torch.Size([37811, 1, 19])\n",
      "Test set: torch.Size([36138, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6637, Val Loss: 0.6650, Val Accuracy: 0.7046\n",
      "Epoch [20/100], Loss: 0.6449, Val Loss: 0.6477, Val Accuracy: 0.7046\n",
      "Epoch [30/100], Loss: 0.6209, Val Loss: 0.6258, Val Accuracy: 0.7046\n",
      "Epoch [40/100], Loss: 0.5950, Val Loss: 0.6058, Val Accuracy: 0.7046\n",
      "Epoch [50/100], Loss: 0.5826, Val Loss: 0.6035, Val Accuracy: 0.7046\n",
      "Epoch [60/100], Loss: 0.5803, Val Loss: 0.6040, Val Accuracy: 0.7046\n",
      "Epoch [70/100], Loss: 0.5750, Val Loss: 0.5979, Val Accuracy: 0.7046\n",
      "Epoch [80/100], Loss: 0.5706, Val Loss: 0.5942, Val Accuracy: 0.7046\n",
      "Epoch [90/100], Loss: 0.5644, Val Loss: 0.5907, Val Accuracy: 0.7046\n",
      "Epoch [100/100], Loss: 0.5562, Val Loss: 0.5853, Val Accuracy: 0.7046\n",
      "{'dataset': 'type5_label', 'LSTM_VAL_LOSS': 0.5852553248405457, 'LSTM_VAL_ACC': 0.7045833223136124, 'LSTM_Test_LOSS': 0.5888463258743286, 'LSTM_Test_ACC': 0.7063478886490675}\n",
      "type6_label\n",
      "Train set: torch.Size([136087, 1, 19])\n",
      "Validation set: torch.Size([55452, 1, 19])\n",
      "Test set: torch.Size([49782, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6925, Val Loss: 0.6921, Val Accuracy: 0.5888\n",
      "Epoch [20/100], Loss: 0.6765, Val Loss: 0.6852, Val Accuracy: 0.5888\n",
      "Epoch [30/100], Loss: 0.6548, Val Loss: 0.6780, Val Accuracy: 0.5888\n",
      "Epoch [40/100], Loss: 0.6277, Val Loss: 0.6764, Val Accuracy: 0.5888\n",
      "Epoch [50/100], Loss: 0.6082, Val Loss: 0.6948, Val Accuracy: 0.5888\n",
      "Epoch [60/100], Loss: 0.6048, Val Loss: 0.7109, Val Accuracy: 0.5888\n",
      "Epoch [70/100], Loss: 0.5984, Val Loss: 0.6939, Val Accuracy: 0.5888\n",
      "Epoch [80/100], Loss: 0.5924, Val Loss: 0.6811, Val Accuracy: 0.5888\n",
      "Epoch [90/100], Loss: 0.5844, Val Loss: 0.6755, Val Accuracy: 0.5888\n",
      "Epoch [100/100], Loss: 0.5734, Val Loss: 0.6647, Val Accuracy: 0.5888\n",
      "{'dataset': 'type6_label', 'LSTM_VAL_LOSS': 0.6647210121154785, 'LSTM_VAL_ACC': 0.5888335858039385, 'LSTM_Test_LOSS': 0.6199284195899963, 'LSTM_Test_ACC': 0.6435659475312362}\n",
      "type7_label\n",
      "Train set: torch.Size([133322, 1, 19])\n",
      "Validation set: torch.Size([44147, 1, 19])\n",
      "Test set: torch.Size([56693, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6719, Val Loss: 0.6688, Val Accuracy: 0.6482\n",
      "Epoch [20/100], Loss: 0.6646, Val Loss: 0.6596, Val Accuracy: 0.6482\n",
      "Epoch [30/100], Loss: 0.6571, Val Loss: 0.6495, Val Accuracy: 0.6482\n",
      "Epoch [40/100], Loss: 0.6518, Val Loss: 0.6425, Val Accuracy: 0.6482\n",
      "Epoch [50/100], Loss: 0.6482, Val Loss: 0.6405, Val Accuracy: 0.6482\n",
      "Epoch [60/100], Loss: 0.6423, Val Loss: 0.6392, Val Accuracy: 0.6482\n",
      "Epoch [70/100], Loss: 0.6334, Val Loss: 0.6359, Val Accuracy: 0.6482\n",
      "Epoch [80/100], Loss: 0.6185, Val Loss: 0.6298, Val Accuracy: 0.6482\n",
      "Epoch [90/100], Loss: 0.5964, Val Loss: 0.6217, Val Accuracy: 0.6493\n",
      "Epoch [100/100], Loss: 0.5670, Val Loss: 0.6114, Val Accuracy: 0.6678\n",
      "{'dataset': 'type7_label', 'LSTM_VAL_LOSS': 0.6113580465316772, 'LSTM_VAL_ACC': 0.6678143475207828, 'LSTM_Test_LOSS': 0.5868951082229614, 'LSTM_Test_ACC': 0.6260208491348138}\n",
      "type8_label\n",
      "Train set: torch.Size([149449, 1, 19])\n",
      "Validation set: torch.Size([71191, 1, 19])\n",
      "Test set: torch.Size([45160, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6909, Val Loss: 0.6973, Val Accuracy: 0.4125\n",
      "Epoch [20/100], Loss: 0.6826, Val Loss: 0.7088, Val Accuracy: 0.4125\n",
      "Epoch [30/100], Loss: 0.6741, Val Loss: 0.7267, Val Accuracy: 0.4125\n",
      "Epoch [40/100], Loss: 0.6665, Val Loss: 0.7455, Val Accuracy: 0.4125\n",
      "Epoch [50/100], Loss: 0.6579, Val Loss: 0.7467, Val Accuracy: 0.4125\n",
      "Epoch [60/100], Loss: 0.6444, Val Loss: 0.7282, Val Accuracy: 0.4125\n",
      "Epoch [70/100], Loss: 0.6230, Val Loss: 0.7036, Val Accuracy: 0.4125\n",
      "Epoch [80/100], Loss: 0.5900, Val Loss: 0.6708, Val Accuracy: 0.4612\n",
      "Epoch [90/100], Loss: 0.5449, Val Loss: 0.6183, Val Accuracy: 0.6360\n",
      "Epoch [100/100], Loss: 0.4905, Val Loss: 0.5546, Val Accuracy: 0.7102\n",
      "{'dataset': 'type8_label', 'LSTM_VAL_LOSS': 0.5546097755432129, 'LSTM_VAL_ACC': 0.7102021322920032, 'LSTM_Test_LOSS': 0.5199935436248779, 'LSTM_Test_ACC': 0.695925597874225}\n",
      "type9_label\n",
      "Train set: torch.Size([135958, 1, 19])\n",
      "Validation set: torch.Size([46129, 1, 19])\n",
      "Test set: torch.Size([48291, 1, 19])\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(19, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch [10/100], Loss: 0.6930, Val Loss: 0.6908, Val Accuracy: 0.8369\n",
      "Epoch [20/100], Loss: 0.6732, Val Loss: 0.6720, Val Accuracy: 0.6934\n",
      "Epoch [30/100], Loss: 0.6451, Val Loss: 0.6447, Val Accuracy: 0.6934\n",
      "Epoch [40/100], Loss: 0.6093, Val Loss: 0.6107, Val Accuracy: 0.6934\n",
      "Epoch [50/100], Loss: 0.5845, Val Loss: 0.5906, Val Accuracy: 0.6934\n",
      "Epoch [60/100], Loss: 0.5841, Val Loss: 0.5916, Val Accuracy: 0.6934\n",
      "Epoch [70/100], Loss: 0.5798, Val Loss: 0.5858, Val Accuracy: 0.6934\n",
      "Epoch [80/100], Loss: 0.5771, Val Loss: 0.5818, Val Accuracy: 0.6934\n",
      "Epoch [90/100], Loss: 0.5738, Val Loss: 0.5771, Val Accuracy: 0.6934\n",
      "Epoch [100/100], Loss: 0.5699, Val Loss: 0.5713, Val Accuracy: 0.6934\n",
      "{'dataset': 'type9_label', 'LSTM_VAL_LOSS': 0.571347177028656, 'LSTM_VAL_ACC': 0.6934249604370353, 'LSTM_Test_LOSS': 0.6156542897224426, 'LSTM_Test_ACC': 0.6858627901679402}\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for file_path in xlsx_files:\n",
    "    # print(file_path)\n",
    "    results = {}\n",
    "    label_key = os.path.basename(file_path).split('.')[0][:-28]\n",
    "    print(label_key)\n",
    "    results['dataset'] = label_key\n",
    "    \n",
    "    data = pd.read_excel(file_path)\n",
    "    \n",
    "    X_train,y_train,X_val,y_val, X_test,y_test = feature_analysis_lstm(data)\n",
    "\n",
    "    val_loss, test_loss,test_accuracy,val_accuracy,model = lstm_approach(X_train,y_train,X_val,y_val, X_test,y_test)\n",
    "    \n",
    "    results['LSTM_VAL_LOSS'] = val_loss\n",
    "    results['LSTM_VAL_ACC'] = val_accuracy\n",
    "    results['LSTM_Test_LOSS'] = test_loss\n",
    "    results['LSTM_Test_ACC'] = test_accuracy\n",
    "\n",
    "    results_list.append(results)\n",
    "    # results_df = results_df.append(results, ignore_index=True)\n",
    "    print(results)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac4740fa-7c82-4a57-86e7-755ed0a2b3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1786368489265442"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e14f0d2-bf9c-4d27-bed1-8fc6a044a12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>LSTM_VAL_LOSS</th>\n",
       "      <th>LSTM_VAL_ACC</th>\n",
       "      <th>LSTM_Test_LOSS</th>\n",
       "      <th>LSTM_Test_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type10_label</td>\n",
       "      <td>0.842691</td>\n",
       "      <td>0.448783</td>\n",
       "      <td>0.607108</td>\n",
       "      <td>0.697908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type1_label</td>\n",
       "      <td>0.225007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422737</td>\n",
       "      <td>0.819507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type2_label</td>\n",
       "      <td>0.574738</td>\n",
       "      <td>0.700146</td>\n",
       "      <td>0.463296</td>\n",
       "      <td>0.799758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type3_label</td>\n",
       "      <td>0.363148</td>\n",
       "      <td>0.922017</td>\n",
       "      <td>0.334697</td>\n",
       "      <td>0.931749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>type4_label</td>\n",
       "      <td>0.571547</td>\n",
       "      <td>0.730036</td>\n",
       "      <td>0.471944</td>\n",
       "      <td>0.812117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type5_label</td>\n",
       "      <td>0.585255</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.588846</td>\n",
       "      <td>0.706348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>type6_label</td>\n",
       "      <td>0.664721</td>\n",
       "      <td>0.588834</td>\n",
       "      <td>0.619928</td>\n",
       "      <td>0.643566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>type7_label</td>\n",
       "      <td>0.611358</td>\n",
       "      <td>0.667814</td>\n",
       "      <td>0.586895</td>\n",
       "      <td>0.626021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>type8_label</td>\n",
       "      <td>0.554610</td>\n",
       "      <td>0.710202</td>\n",
       "      <td>0.519994</td>\n",
       "      <td>0.695926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>type9_label</td>\n",
       "      <td>0.571347</td>\n",
       "      <td>0.693425</td>\n",
       "      <td>0.615654</td>\n",
       "      <td>0.685863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset  LSTM_VAL_LOSS  LSTM_VAL_ACC  LSTM_Test_LOSS  LSTM_Test_ACC\n",
       "0  type10_label       0.842691      0.448783        0.607108       0.697908\n",
       "1   type1_label       0.225007      1.000000        0.422737       0.819507\n",
       "2   type2_label       0.574738      0.700146        0.463296       0.799758\n",
       "3   type3_label       0.363148      0.922017        0.334697       0.931749\n",
       "4   type4_label       0.571547      0.730036        0.471944       0.812117\n",
       "5   type5_label       0.585255      0.704583        0.588846       0.706348\n",
       "6   type6_label       0.664721      0.588834        0.619928       0.643566\n",
       "7   type7_label       0.611358      0.667814        0.586895       0.626021\n",
       "8   type8_label       0.554610      0.710202        0.519994       0.695926\n",
       "9   type9_label       0.571347      0.693425        0.615654       0.685863"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dc98233-1990-4b30-a362-5e36fc9f5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'results_LSTM_v2.xlsx'\n",
    "results_df.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c091b8-b185-4d0f-a24c-4cbb58a67709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8496e-d9ce-401f-b8d3-7f2d7b9abc48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bbd03b-6461-460f-800a-81f7bacd2ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678565c4-d5fe-41f1-8952-1222be4f9161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e0de2-6aae-48ed-ac2c-efd9d06c7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    val_outputs = model(X_val_tensor)\n",
    "    val_loss = criterion(val_outputs, y_val_tensor)\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef4b38-eb9a-43ab-81aa-0d5915614928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_outputs = model(X_test_tensor)\n",
    "test_loss = criterion(test_outputs, y_test_tensor)\n",
    "\n",
    "print(f'Test MSE: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f08346-fc85-4cb6-9e4f-0eb32cc0b418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uavcan_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
